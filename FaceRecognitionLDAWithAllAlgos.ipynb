{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "579iF9uBI3JP"
      },
      "source": [
        "### Google Drive Mounting and File Paths Setup in Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmn9gCJMme4R",
        "outputId": "67826064-e348-44a9-e7ed-1ecf9f80a09c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Mounting the Google drive\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XdI7eOZmqRv"
      },
      "outputs": [],
      "source": [
        "root_path = \"/content/drive/MyDrive/Colab Notebooks/COEN240_TA/\"\n",
        "train_path = root_path + \"train/\"\n",
        "validate_path = root_path + \"validate/\"\n",
        "test_path = root_path + \"test/\"\n",
        "new_path = \"/content/drive/MyDrive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-WjGI8rGtY8"
      },
      "outputs": [],
      "source": [
        "with open(train_path + 'train_cleaned_final.npy', 'rb') as f:\n",
        "    trainX = np.load(f)\n",
        "    trainY = np.load(f)\n",
        "\n",
        "with open(validate_path + 'validate_cleaned_final.npy', 'rb') as f:\n",
        "    testX = np.load(f)\n",
        "    testY = np.load(f)\n",
        "\n",
        "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
        "print(trainX.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Applying PCA"
      ],
      "metadata": {
        "id": "trMz--mUnLx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from skimage.exposure import rescale_intensity\n",
        "from imutils import build_montages\n",
        "\n",
        "import time\n",
        "\n",
        "print(\"[INFO] creating eigenfaces...\")\n",
        "pca = PCA(\n",
        "\tsvd_solver=\"randomized\",\n",
        "\tn_components=100,\n",
        "\twhiten=True)\n",
        "start = time.time()\n",
        "trainX_PCA = pca.fit_transform(trainX)\n",
        "end = time.time()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2vLfxjinO52",
        "outputId": "26e492ec-9d04-47e0-d81c-1185ef5c02d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] creating eigenfaces...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testX_PCA = pca.transform(testX)"
      ],
      "metadata": {
        "id": "q1WXK0BHtG4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainX.shape)\n",
        "print(trainX_PCA.shape)\n",
        "print(testX_PCA.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9xXWc4fqTeM",
        "outputId": "6833539e-0b71-40aa-dc20-4a49931c04c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10289, 40000)\n",
            "(10289, 100)\n",
            "(1781, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### LDA on PCA"
      ],
      "metadata": {
        "id": "4gR_qQyaqmHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "\n",
        "# Fit LDA to the training data\n",
        "trainX_LDA = lda.fit_transform(trainX_PCA, trainY)"
      ],
      "metadata": {
        "id": "EG4_Q-3VqfdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testX_LDA = lda.transform(testX_PCA)"
      ],
      "metadata": {
        "id": "3XFHto8otRDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHyPJSz1zg3Y",
        "outputId": "0d7e158c-36b2-4214-c17e-34cf25f4ae6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dimensions: (10289, 40000)\n",
            "Reduced Dimensions PCA: (10289, 100)\n",
            "Reduced Dimensions LDA on PCA: (10289, 31)\n",
            "labels dim: (10289,)\n",
            "testX: (1781, 40000)\n"
          ]
        }
      ],
      "source": [
        "print(\"Original Dimensions:\", trainX.shape)\n",
        "print(\"Reduced Dimensions PCA:\", trainX_PCA.shape)\n",
        "print(\"Reduced Dimensions LDA on PCA:\", trainX_LDA.shape)\n",
        "print(\"labels dim:\", trainY.shape)\n",
        "print(\"testX:\",testX.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6eWWqwk3s-T"
      },
      "source": [
        "## Applying models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt3CTzP03wBq"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the training data\n",
        "trainX_scaled = scaler.fit_transform(trainX_LDA)\n",
        "\n",
        "# Transform the test data using the same scaler\n",
        "testX_scaled = scaler.transform(testX_LDA)\n",
        "\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {'n_neighbors': [3, 5, 7, 9],\n",
        "              'weights': ['uniform', 'distance'],\n",
        "              'p': [1, 2]}\n",
        "\n",
        "# Create the KNN model\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "# Use GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(knn_model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(trainX_LDA, trainY)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Train the KNN model with the best hyperparameters\n",
        "best_knn_model = KNeighborsClassifier(**best_params)\n",
        "best_knn_model.fit(trainX_LDA, trainY)\n",
        "\n",
        "# Make predictions and calculate accuracy\n",
        "best_knn_predictions = best_knn_model.predict(testX_LDA)\n",
        "best_knn_accuracy = accuracy_score(testY, best_knn_predictions)\n",
        "print(\"Best KNN Accuracy:\", best_knn_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px8QAyQjrv3H",
        "outputId": "8b79a941-7b1e-441b-d1ef-6ec246fb8ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_neighbors': 3, 'p': 2, 'weights': 'distance'}\n",
            "Best KNN Accuracy: 0.9320606400898371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {'n_neighbors': [3, 5, 7, 9],\n",
        "              'weights': ['uniform', 'distance'],\n",
        "              'p': [1, 2]}\n",
        "\n",
        "# Use GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(knn_model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(trainX_LDA, trainY)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Train the KNN model with the best hyperparameters\n",
        "best_knn_model = KNeighborsClassifier(**best_params)\n",
        "best_knn_model.fit(trainX_LDA, trainY)\n",
        "\n",
        "# Training Score\n",
        "train_score = best_knn_model.score(trainX_LDA, trainY)\n",
        "print(\"Training Score:\", train_score)\n",
        "\n",
        "# Make predictions and calculate accuracy\n",
        "best_knn_predictions = best_knn_model.predict(testX_LDA)\n",
        "best_knn_accuracy = accuracy_score(testY, best_knn_predictions)\n",
        "print(\"Best KNN Accuracy:\", best_knn_accuracy)\n",
        "\n",
        "# Calculate precision, recall, and f1-score\n",
        "precision = precision_score(testY, best_knn_predictions, average='weighted')\n",
        "recall = recall_score(testY, best_knn_predictions, average='weighted')\n",
        "f1 = f1_score(testY, best_knn_predictions, average='weighted')\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1to1pfafpaHW",
        "outputId": "87a92b5a-24e2-4694-976a-008e3b178641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_neighbors': 3, 'p': 2, 'weights': 'distance'}\n",
            "Training Score: 1.0\n",
            "Best KNN Accuracy: 0.9320606400898371\n",
            "Precision: 0.9408369455468092\n",
            "Recall: 0.9320606400898371\n",
            "F1-Score: 0.9301185530221724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM RBF"
      ],
      "metadata": {
        "id": "TJvfxDnM0GaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Define the parameter grid for SVM with RBF kernel\n",
        "param_grid_svm = {'C': [0.1, 1, 10],\n",
        "                  'gamma': [0.001, 0.01, 0.1, 1],\n",
        "                  'kernel': ['rbf']}\n",
        "\n",
        "# Create the SVM model with RBF kernel\n",
        "svm_model = SVC()\n",
        "\n",
        "# Use GridSearchCV to find the best hyperparameters\n",
        "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, scoring='accuracy')\n",
        "grid_search_svm.fit(trainX_LDA, trainY)\n",
        "\n",
        "# Get the best parameters for SVM\n",
        "best_params_svm = grid_search_svm.best_params_\n",
        "print(\"Best Hyperparameters for SVM:\", best_params_svm)\n",
        "\n",
        "# Train the SVM model with the best hyperparameters\n",
        "best_svm_model = SVC(**best_params_svm)\n",
        "best_svm_model.fit(trainX_LDA, trainY)\n",
        "\n",
        "# Make predictions and calculate accuracy for SVM\n",
        "best_svm_predictions = best_svm_model.predict(testX_LDA)\n",
        "best_svm_accuracy = accuracy_score(testY, best_svm_predictions)\n",
        "print(\"Best SVM Accuracy:\", best_svm_accuracy)\n",
        "\n",
        "# Training Score\n",
        "train_score = best_svm_model.score(trainX_LDA, trainY)\n",
        "print(\"Training Score for SVM:\", train_score)\n",
        "\n",
        "# Precision, Recall, and F1-Score\n",
        "precision = precision_score(testY, best_svm_predictions, average='weighted')\n",
        "recall = recall_score(testY, best_svm_predictions, average='weighted')\n",
        "f1 = f1_score(testY, best_svm_predictions, average='weighted')\n",
        "\n",
        "print(\"Precision for SVM:\", precision)\n",
        "print(\"Recall for SVM:\", recall)\n",
        "print(\"F1-Score for SVM:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMMj5q2z0Ijh",
        "outputId": "6771615d-1f8f-429b-f412-46d2590937fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters for SVM: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Best SVM Accuracy: 0.9371139809096013\n",
            "Training Score for SVM: 0.9999028088249587\n",
            "Precision for SVM: 0.9421626100929031\n",
            "Recall for SVM: 0.9371139809096013\n",
            "F1-Score for SVM: 0.9352613333660087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7TnJSQr7vXcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the parameter grid for Logistic Regression\n",
        "param_grid_logreg = {'C': [0.1, 1, 10],\n",
        "                     'penalty': ['l2'],  # Use 'l2' penalty for lbfgs solver\n",
        "                     'max_iter': [100, 200, 300]}  # Increase max_iter\n",
        "\n",
        "# Create the Logistic Regression model\n",
        "logreg_model = LogisticRegression(solver='lbfgs')  # Specify lbfgs solver\n",
        "\n",
        "# Use GridSearchCV to find the best hyperparameters\n",
        "grid_search_logreg = GridSearchCV(logreg_model, param_grid_logreg, cv=5, scoring='accuracy')\n",
        "grid_search_logreg.fit(trainX_LDA, trainY)\n",
        "\n",
        "# Get the best parameters for Logistic Regression\n",
        "best_params_logreg = grid_search_logreg.best_params_\n",
        "print(\"Best Hyperparameters for Logistic Regression:\", best_params_logreg)\n",
        "\n",
        "# Train the Logistic Regression model with the best hyperparameters\n",
        "best_logreg_model = LogisticRegression(**best_params_logreg, solver='lbfgs')  # Specify lbfgs solver\n",
        "best_logreg_model.fit(trainX_LDA, trainY)\n",
        "\n",
        "# Make predictions and calculate accuracy for Logistic Regression\n",
        "best_logreg_predictions = best_logreg_model.predict(testX_LDA)\n",
        "best_logreg_accuracy = accuracy_score(testY, best_logreg_predictions)\n",
        "print(\"Best Logistic Regression Accuracy:\", best_logreg_accuracy)\n",
        "\n",
        "# Calculate training score\n",
        "train_logreg_score = best_logreg_model.score(trainX_LDA, trainY)\n",
        "\n",
        "\n",
        "# Calculate precision, recall, and F1-score for test set\n",
        "precision_test = precision_score(testY, best_logreg_predictions, average='weighted')\n",
        "recall_test = recall_score(testY, best_logreg_predictions, average='weighted')\n",
        "f1_test = f1_score(testY, best_logreg_predictions, average='weighted')\n",
        "\n",
        "# Print the results\n",
        "print(\"Logistic Regression Precision (Test):\", precision_test)\n",
        "print(\"Logistic Regression Recall (Test):\", recall_test)\n",
        "print(\"Logistic Regression F1-Score (Test):\", f1_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3E9eRqEvar8",
        "outputId": "c2d74001-8bf1-43dd-d6d3-aa904617c85e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters for Logistic Regression: {'C': 1, 'max_iter': 200, 'penalty': 'l2'}\n",
            "Best Logistic Regression Accuracy: 0.914093206064009\n",
            "Logistic Regression Precision (Test): 0.9163647550262675\n",
            "Logistic Regression Recall (Test): 0.914093206064009\n",
            "Logistic Regression F1-Score (Test): 0.9122309936030805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_logreg_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoqtRHqEv5xv",
        "outputId": "278bcdfc-6525-499d-bda2-23b51efc31de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9705510739624842"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensemble - KNN, SVM"
      ],
      "metadata": {
        "id": "GDRLlhKwsMZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Create KNN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3, p=2, weights='distance')  # You can adjust the parameters accordingly\n",
        "\n",
        "# Create SVM model\n",
        "svm_model = SVC(C=1, gamma=0.01, kernel='rbf',probability=True)  # Use the best hyperparameters or tune them\n",
        "\n",
        "# Create an ensemble using a soft voting strategy\n",
        "ensemble_model1 = VotingClassifier(estimators=[('knn', knn_model), ('svm', svm_model)], voting='soft')\n",
        "\n",
        "# Fit the ensemble model on the training data\n",
        "ensemble_model1.fit(trainX_LDA, trainY)\n",
        "\n",
        "# Make predictions and calculate accuracy for the ensemble\n",
        "ensemble_predictions = ensemble_model1.predict(testX_LDA)\n",
        "ensemble_accuracy = accuracy_score(testY, ensemble_predictions)\n",
        "print(\"Ensemble Accuracy:\", ensemble_accuracy)\n",
        "\n",
        "# Calculate and print ensemble training score\n",
        "ensemble_train_score = ensemble_model1.score(trainX_LDA, trainY)\n",
        "print(\"Ensemble Training Score:\", ensemble_train_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4_e5834sRgo",
        "outputId": "1f412174-5297-49a0-d084-7b96f518aa8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Accuracy: 0.9460976979225154\n",
            "Ensemble Training Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensemble - KNN, SVM, Logistic Regression"
      ],
      "metadata": {
        "id": "cn36bRoS03wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming you have already defined trainX_LDA, testX_LDA, trainY, and testY\n",
        "# Assuming you have standardized your data using StandardScaler\n",
        "\n",
        "# Create KNN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3, p=2, weights='distance')  # You can adjust the parameters accordingly\n",
        "\n",
        "# Create SVM model\n",
        "svm_model = SVC(C=1, gamma=0.01, kernel='rbf', probability=True)  # Use the best hyperparameters or tune them\n",
        "\n",
        "# Create Logistic Regression model\n",
        "logreg_model = LogisticRegression(C=0.1, max_iter=100, penalty='l2')  # Parameters provided\n",
        "\n",
        "# Create an ensemble using a soft voting strategy\n",
        "ensemble_model = VotingClassifier(estimators=[('knn', knn_model), ('svm', svm_model), ('logreg', logreg_model)], voting='soft')\n",
        "\n",
        "# Fit the ensemble model on the training data\n",
        "ensemble_model.fit(trainX_LDA, trainY)\n",
        "\n",
        "# Make predictions and calculate accuracy for the ensemble\n",
        "ensemble_predictions = ensemble_model.predict(testX_LDA)\n",
        "ensemble_accuracy = accuracy_score(testY, ensemble_predictions)\n",
        "print(\"Ensemble Accuracy:\", ensemble_accuracy)\n",
        "\n",
        "# Calculate and print ensemble training score\n",
        "ensemble_train_score = ensemble_model.score(trainX_LDA, trainY)\n",
        "print(\"Ensemble Training Score:\", ensemble_train_score)\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Specify the full path for saving the model\n",
        "file_path = root_path+\"ensemble_model2.pkl\"\n",
        "\n",
        "# Save the trained ensemble model to the specified location\n",
        "with open(file_path, 'wb') as file:\n",
        "    pickle.dump(ensemble_model2, file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGFdjDt_078h",
        "outputId": "f0fa8cb1-9adf-40b5-df9c-06fd73d77097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Accuracy: 0.9466591802358225\n",
            "Ensemble Training Score: 0.9970842647487608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F1 Score, Precision, Recall"
      ],
      "metadata": {
        "id": "Bn4WlhMmarR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Make predictions on the test set\n",
        "# ensemble_predictions1 = ensemble_model1.predict(testX_LDA)\n",
        "\n",
        "# # Define class names\n",
        "# class_names = [\n",
        "#     \"amarisian\", \"banmingkai\", \"chenziang\", \"chientingwei\", \"gowdarachandrashekarappasrivarsha\",\n",
        "#     \"huangjiaoyan\", \"kodipunzulanandini\", \"lishumeng\", \"liuhongji\", \"lozanoroberto\",\n",
        "#     \"manglaniroshanlakhi\", \"mendonakshay\", \"negiparth\", \"oraisisaac\", \"perambuduruvishnu\",\n",
        "#     \"pereiranerissagodfrey\", \"ravijayanthidhanasekar\", \"sampagaonrahul\", \"selinayu\", \"shahmanali\",\n",
        "#     \"sivarajusairevanth\", \"somaniachal\", \"upadhyevaishnavi\", \"vanderlindenilona\",\n",
        "#     \"vennavellirajashekarreddy\", \"virvadianisargjyotin\", \"wukaiyue\", \"yashasvi\", \"zhangyuanzhen\",\n",
        "#     \"zhouchuandi\", \"zotaharsh\", \"zuluagagonzalezisabel\"\n",
        "# ]\n",
        "\n",
        "# # Compute precision, recall, and f1 score\n",
        "# precision = precision_score(testY, ensemble_predictions1, average='weighted')\n",
        "# recall = recall_score(testY, ensemble_predictions1, average='weighted')\n",
        "# f1 = f1_score(testY, ensemble_predictions1, average='weighted')\n",
        "\n",
        "# print(\"Precision:\", precision)\n",
        "# print(\"Recall:\", recall)\n",
        "# print(\"F1 Score:\", f1)\n",
        "\n",
        "# # # Create a confusion matrix heatmap\n",
        "# # cm = confusion_matrix(testY, ensemble_predictions)\n",
        "# # plt.figure(figsize=(10, 8))\n",
        "# # sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "# # plt.title(\"Confusion Matrix\")\n",
        "# # plt.xlabel(\"Predicted\")\n",
        "# # plt.ylabel(\"True\")\n",
        "# # plt.show()\n",
        "\n",
        "# # # Display the classification report with class names\n",
        "# # print(\"Classification Report:\")\n",
        "# # print(classification_report(testY, ensemble_predictions, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw94bLePa0dK",
        "outputId": "fa60f5be-5e67-49bf-c217-e5f5b7bea750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9522166833269612\n",
            "Recall: 0.9466591802358225\n",
            "F1 Score: 0.9453336951180759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "\n",
        "# # Save the trained SVM model to a Pickle file\n",
        "# with open(new_path + 'model1.pkl', 'wb') as file:\n",
        "#     pickle.dump(ensemble_model1, file)\n"
      ],
      "metadata": {
        "id": "lL5wb6W_OtQP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}